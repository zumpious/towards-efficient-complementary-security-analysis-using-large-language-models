{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPOTBUGS_DATASET_PATH = '../owasp_benchmark/spotbugs_dataset.pkl'\n",
    "spotbugs_dataset = pd.read_pickle(SPOTBUGS_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_gemini_1_0 = \"experiment_3_config2__few_shot_CoT__gemini-1.0-pro-002_2024.07.01_10-30-08_403.json\"\n",
    "filename_gemini_1_5 = \"experiment_3_config2__few_shot_CoT__gemini-1.5-pro-001_2024.07.01_14-56-04_403.json\"\n",
    "filename_llama3_8b = \"experiment_3_config2__few_shot_CoT__meta-llama-Meta-Llama-3-8B-Instruct_2024.07.05_18-10-14_403.json\"\n",
    "filename_llama31_70b = \"experiment_3_config2__few_shot_CoT__hugging-quants-Meta-Llama-3.1-70B-Instruct-AWQ-INT4_2024.07.26_00-52-40_403.json\"\n",
    "filename_gpt4o = \"experiment_3_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.06.19_00-54-42_403.json\"\n",
    "filename_gpt35_turbo = \"experiment_3_config2__few_shot_CoT__gpt-35-turbo_2024.06.24_13-52-02_403.json\"\n",
    "filename_phi3_medium = \"experiment_3_config2__few_shot_CoT__microsoft-Phi-3-medium-128k-instruct_2024.07.11_23-48-57_403.json\"\n",
    "filename_phi4 = \"experiment_3_config2__few_shot_CoT__microsoft-phi-4_2025.01.20_17-53-56_403.json\"\n",
    "filename_qwen15_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-7B-Chat_2025.01.04_16-12-46_403.json\"\n",
    "filename_qwen15_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-14B-Chat-GPTQ-Int4_2025.01.04_19-17-19_403.json\"\n",
    "filename_qwen15_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-14B-Chat-GPTQ-Int4_2025.01.04_19-17-19_403.json\"\n",
    "filename_qwen15_32b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-32B-Chat-GPTQ-Int4_2025.01.04_18-10-00_403.json\"\n",
    "filename_qwen2_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2-7B-Instruct_2025.01.04_00-28-55_403.json\"\n",
    "filename_qwen2_72b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2-72B-Instruct-GPTQ-Int4_2025.01.20_15-37-51_403.json\"\n",
    "filename_qwen25_05b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-0.5B-Instruct_2024.12.30_18-19-37_403.json\"\n",
    "filename_qwen25_1b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-1.5B-Instruct_2024.12.30_18-02-42_403.json\"\n",
    "filename_qwen25_3b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-3B-Instruct_2024.12.30_15-16-53_403.json\"\n",
    "filename_qwen25_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-7B-Instruct_2024.12.30_13-52-47_403.json\"\n",
    "filename_qwen25_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-14B-Instruct-GPTQ-Int4_2024.12.30_19-26-54_403.json\"\n",
    "filename_qwen25_32b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2024.12.31_00-11-19_403.json\"\n",
    "filename_qwen25_72b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-72B-Instruct-GPTQ-Int8_2025.01.25_17-59-59_403.json\"\n",
    "filename_qwen25_coder_05b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-0.5B-Instruct_2025.01.03_16-12-41_403.json\"\n",
    "filename_qwen25_coder_1b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-1.5B-Instruct_2025.01.03_16-34-53_403.json\"\n",
    "filename_qwen25_coder_3b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-3B-Instruct_2025.01.03_17-13-41_403.json\"\n",
    "filename_qwen25_coder_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-7B-Instruct_2025.01.03_18-51-15_403.json\"\n",
    "filename_qwen25_coder_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-14B-Instruct-GPTQ-Int4_2025.01.03_21-02-19_403.json\"\n",
    "filename_qwen25_coder_32b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-32B-Instruct-GPTQ-Int4_2025.01.03_23-18-16_403.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load = (\n",
    "    (os.path.join(RESULTS_PATH, filename_gemini_1_0), \"gemini_1_0\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_gemini_1_5), \"gemini_1_5\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_llama3_8b), \"llama3_8b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_llama31_70b), \"llama31_70b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_gpt4o), \"gpt_4o\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_gpt35_turbo), \"gpt35_turbo\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_phi3_medium), \"phi3_medium\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_phi4), \"phi_4\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen15_7b), \"qwen15_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen15_14b), \"qwen15_14b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen15_32b), \"qwen15_32b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen2_7b), \"qwen2_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen2_72b), \"qwen2_72b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_05b), \"qwen2.5_05b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_1b), \"qwen2.5_1b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_3b), \"qwen2.5_3b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_7b), \"qwen2.5_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_14b), \"qwen2.5_14b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_32b), \"qwen2.5_32b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_72b), \"qwen2.5_72b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_05b), \"qwen2.5_coder_05b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_1b), \"qwen2.5_coder_1b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_3b), \"qwen2.5_coder_3b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_7b), \"qwen2.5_coder_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_14b), \"qwen2.5_coder_14b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_32b), \"qwen2.5_coder_32b\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "for file_path, df_name in files_to_load:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD = 2\n",
    "choices = ['TP', 'FP', 'TN', 'FN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for gemini_1_0 on OWASP Benchmark test split:\n",
      "TP    269\n",
      "FP    113\n",
      "TN     15\n",
      "FN      6\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for gemini_1_5 on OWASP Benchmark test split:\n",
      "TP    266\n",
      "FP     28\n",
      "TN    100\n",
      "FN      9\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for llama3_8b on OWASP Benchmark test split:\n",
      "TP    274\n",
      "FP    119\n",
      "TN      9\n",
      "FN      1\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for llama31_70b on OWASP Benchmark test split:\n",
      "TP    251\n",
      "FP     16\n",
      "TN    112\n",
      "FN     24\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for gpt_4o on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP     78\n",
      "TN     50\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for gpt35_turbo on OWASP Benchmark test split:\n",
      "TP    271\n",
      "FP    113\n",
      "TN     15\n",
      "FN      4\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for phi3_medium on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP    112\n",
      "TN     16\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for phi_4 on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP     52\n",
      "TN     76\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen15_7b on OWASP Benchmark test split:\n",
      "TP    272\n",
      "FP    127\n",
      "TN      1\n",
      "FN      3\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen15_14b on OWASP Benchmark test split:\n",
      "TP    259\n",
      "FP    106\n",
      "TN     22\n",
      "FN     16\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen15_32b on OWASP Benchmark test split:\n",
      "TP    263\n",
      "FP     95\n",
      "TN     33\n",
      "FN     12\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2_7b on OWASP Benchmark test split:\n",
      "TP    268\n",
      "FP    104\n",
      "TN     24\n",
      "FN      7\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2_72b on OWASP Benchmark test split:\n",
      "TP    274\n",
      "FP     83\n",
      "TN     45\n",
      "FN      1\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_05b on OWASP Benchmark test split:\n",
      "TP    233\n",
      "FP    112\n",
      "TN     16\n",
      "FN     42\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_1b on OWASP Benchmark test split:\n",
      "TP    266\n",
      "FP    119\n",
      "TN      9\n",
      "FN      9\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_3b on OWASP Benchmark test split:\n",
      "TP    268\n",
      "FP    116\n",
      "TN     12\n",
      "FN      7\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_7b on OWASP Benchmark test split:\n",
      "TP    269\n",
      "FP    118\n",
      "TN     10\n",
      "FN      6\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_14b on OWASP Benchmark test split:\n",
      "TP    272\n",
      "FP     51\n",
      "TN     77\n",
      "FN      3\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_32b on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP     57\n",
      "TN     71\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_72b on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP     80\n",
      "TN     48\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_05b on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP    128\n",
      "TN      0\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_1b on OWASP Benchmark test split:\n",
      "TP    266\n",
      "FP    126\n",
      "TN      2\n",
      "FN      9\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_3b on OWASP Benchmark test split:\n",
      "TP    268\n",
      "FP    123\n",
      "TN      5\n",
      "FN      7\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_7b on OWASP Benchmark test split:\n",
      "TP    274\n",
      "FP    122\n",
      "TN      6\n",
      "FN      1\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_14b on OWASP Benchmark test split:\n",
      "TP    269\n",
      "FP     72\n",
      "TN     56\n",
      "FN      6\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_32b on OWASP Benchmark test split:\n",
      "TP    273\n",
      "FP     59\n",
      "TN     69\n",
      "FN      2\n",
      "Name: llm_classification, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dataframes.values():\n",
    "    df[\"llm_vul_decision\"] = np.where(df[\"threshold_value\"] < 0.0, True, df[\"threshold_value\"] >= TRESHOLD)\n",
    "    \n",
    "    conditions = [\n",
    "        (df[\"real_vulnerability\"] == True) & (df[\"llm_vul_decision\"] == True),\n",
    "        (df[\"real_vulnerability\"] == False) & (df[\"llm_vul_decision\"] == True),\n",
    "        (df[\"real_vulnerability\"] == False) & (df[\"llm_vul_decision\"] == False),\n",
    "        (df[\"real_vulnerability\"] == True) & (df[\"llm_vul_decision\"] == False)\n",
    "    ]\n",
    "    df[\"llm_classification\"] = np.select(conditions, choices)\n",
    "\n",
    "for model, df in dataframes.items():\n",
    "    print(f\"Confusion Matrix for {model} on OWASP Benchmark test split:\")\n",
    "    print(df[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_RESULTS_PATH = 'results/sc/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_phi4_sc1 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.20_17-53-56_403.json\"\n",
    "filename_phi4_sc2 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.21_23-09-57_403.json\"\n",
    "filename_phi4_sc3 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.22_11-03-37_403.json\"\n",
    "filename_phi4_sc4 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.22_12-48-26_403.json\"\n",
    "filename_phi4_sc5 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.22_14-03-20_403.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load_sc_phi4 = (\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc1), \"phi_4 sc1\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc2), \"phi_4 sc2\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc3), \"phi_4 sc3\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc4), \"phi_4 sc4\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc5), \"phi_4 sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_sc_phi4:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD_PHI_4 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= TRESHOLD) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Phi4 SC results on OWASP Benchmark test split\n",
      "TP    275\n",
      "FP     52\n",
      "TN     76\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Phi4 SC results on OWASP Benchmark test split\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qwen 2.5 32B Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_qwen_sc1 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.23_17-22-31_403.json\"\n",
    "filename_qwen_sc2 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.23_23-18-22_403.json\"\n",
    "filename_qwen_sc3 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.24_13-24-46_403.json\"\n",
    "filename_qwen_sc4 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.24_18-09-55_403.json\"\n",
    "filename_qwen_sc5 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2024.12.31_00-11-19_403.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load_sc_qwen25_32b = (\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc1), \"Qwen2.5 sc1\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc2), \"Qwen2.5 sc2\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc3), \"Qwen2.5 sc3\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc4), \"Qwen2.5 sc4\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc5), \"Qwen2.5 sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc_qwen = {}\n",
    "for file_path, df_name in files_to_load_sc_qwen25_32b:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc_qwen[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes_sc_qwen.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD_QWEN25_32B = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Qwen2.5 32B SC results on  OWASP Benchmark test split\n",
      "TP    275\n",
      "FP     48\n",
      "TN     80\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "for _, df in dataframes_sc_qwen.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= TRESHOLD_QWEN25_32B) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent_qwen = list(dataframes_sc_qwen.values())[0].copy()\n",
    "dfs_qwen = list(dataframes_sc_qwen.values())\n",
    "dfs_other = [df for df in dfs_qwen if df is not list(dataframes_sc_qwen.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent_qwen.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs_qwen]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent_qwen.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent_qwen.at[idx, 'llm_vul_decision'] = consensus\n",
    "\n",
    "for _, _ in dataframes_sc_qwen.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == True) & (df_sc_consistent_qwen['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == False) & (df_sc_consistent_qwen['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == False) & (df_sc_consistent_qwen['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == True) & (df_sc_consistent_qwen['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent_qwen['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Qwen2.5 32B SC results on  OWASP Benchmark test split\")\n",
    "print(df_sc_consistent_qwen[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent_qwen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_gpt4o_sc1 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.06.19_00-54-42_403.json\"\n",
    "filename_gpt4o_sc2 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_15-43-27_403.json\"\n",
    "filename_gpt4o_sc3 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_17-49-47_403.json\"\n",
    "filename_gpt4o_sc4 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_18-52-38_403.json\"\n",
    "filename_gpt4o_sc5 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.07_23-14-22_403.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load_sc_gpt4o = (\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc1), \"GPT-4o sc1\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc2), \"GPT-4o sc2\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc3), \"GPT-4o sc3\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc4), \"GPT-4o sc4\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc5), \"GPT-4o sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc_gpt4o = {}\n",
    "for file_path, df_name in files_to_load_sc_gpt4o:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc_gpt4o[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes_sc_gpt4o.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD_GPT4O = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for GPT-4o SC results on  OWASP Benchmark test split\n",
      "TP    275\n",
      "FP     48\n",
      "TN     80\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "for _, df in dataframes_sc_gpt4o.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= TRESHOLD_GPT4O) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent_gpt4o = list(dataframes_sc_gpt4o.values())[0].copy()\n",
    "dfs_gpt4o = list(dataframes_sc_gpt4o.values())\n",
    "dfs_other = [df for df in dfs_gpt4o if df is not list(dataframes_sc_gpt4o.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent_gpt4o.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs_gpt4o]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent_gpt4o.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent_gpt4o.at[idx, 'llm_vul_decision'] = consensus\n",
    "\n",
    "for _, _ in dataframes_sc_gpt4o.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == True) & (df_sc_consistent_gpt4o['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == False) & (df_sc_consistent_gpt4o['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == False) & (df_sc_consistent_gpt4o['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == True) & (df_sc_consistent_gpt4o['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent_gpt4o['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for GPT-4o SC results on  OWASP Benchmark test split\")\n",
    "print(df_sc_consistent_gpt4o[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent_gpt4o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnestix (Real World Dataset)\n",
    "\n",
    "To demonstrate that our approach is not only effective on benchmark datasets but also applicable to real-world security analysis, we applied it to the open-source project Mnestix, developed by XITASO GmbH. This analysis allowed us to validate the approach on actual software weaknesses while ensuring transparency in discussing the findings.\n",
    "\n",
    "We utilized multiple SAST tools to analyze the Mnestix codebase, which includes components written in C, TypeScript, and infrastructure code, as well as BASXY, an open-source Java codebase. The selected tools—CodeQL, Semgrep, SpotBugs with FindSecBugs, Checkov, and KICS—enabled us to cover a broad range of security weaknesses across different programming paradigms. The findings from these SAST tools were manually labeled by different security experts and then assessed by the previously identified best-performing LLMs for our specific use case: GPT-4o, Qwen2.5 32B, and Phi-4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNESTIX Results\n",
    "CHECKOV_MNESTIX_RESULTS_FILE_PATH = \"results/mnestix/tool_results/checkov_labeled_results.xlsx\"\n",
    "CODEQL_MNESTIX_RESULTS_FILE_PATH = \"results/mnestix/tool_results/code_ql_labeled_results.xlsx\"\n",
    "KICS_MNESTIX_RESULTS_FILE_PATH = \"results/mnestix/tool_results/kics_labled_results.xlsx\"\n",
    "SEMGREP_MNESTIX_RESULTS_FILE_PATH = \"results/mnestix/tool_results/semgrep_labeled_results.xlsx\"\n",
    "\n",
    "#BASYX Results\n",
    "SPOTBUGS_AAS_ENV_RESULTS_FILE_PATH = \"results/mnestix/tool_results/spotbugs_aas_env_labeled_report.xlsx\"\n",
    "SPOTBUGS_BASYX_COMPONENTS_RESULTS_FILE_PATH = \"results/mnestix/tool_results/spotbugs_basyx_labeled_report.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkov_mnestix_results = pd.read_excel(CHECKOV_MNESTIX_RESULTS_FILE_PATH)\n",
    "checkov_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "codeql_mnestix_results = pd.read_excel(CODEQL_MNESTIX_RESULTS_FILE_PATH)\n",
    "codeql_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "kics_mnestix_results = pd.read_excel(KICS_MNESTIX_RESULTS_FILE_PATH)\n",
    "kics_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "semgrep_mnestix_results = pd.read_excel(SEMGREP_MNESTIX_RESULTS_FILE_PATH)\n",
    "semgrep_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "spotbugs_aas_env_results = pd.read_excel(SPOTBUGS_AAS_ENV_RESULTS_FILE_PATH)\n",
    "spotbugs_aas_env_results.set_index('id', inplace=True)\n",
    "\n",
    "spotbugs_basyx_components_results = pd.read_excel(SPOTBUGS_BASYX_COMPONENTS_RESULTS_FILE_PATH)\n",
    "spotbugs_basyx_components_results.set_index('id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to every SAST scanner having different column names, we need to map them to a common set of column names\n",
    "relevant_columns = ['scanner', 'category', 'cwe', 'line of code', 'type', 'method', 'file', 'description', 'classification']\n",
    "\n",
    "spotbugs_columns = {\n",
    "    'scanner': 'scanner', \n",
    "    'type': 'type', \n",
    "    'cweid': 'cwe', \n",
    "    'category': 'category', \n",
    "    'method': 'method', \n",
    "    'sourceLine': 'line of code', \n",
    "    'classification': 'classification', \n",
    "    'sourceFile': 'file'\n",
    "}\n",
    "\n",
    "semgrep_columns = {\n",
    "    'scanner': 'scanner', \n",
    "    'cweid': 'cwe', \n",
    "    'category': 'category', \n",
    "    'start_line': 'line of code', \n",
    "    'classification': 'classification', \n",
    "    'path': 'file', \n",
    "    'message': 'description'\n",
    "}\n",
    "\n",
    "kics_columns = {\n",
    "        'scanner': 'scanner', \n",
    "        'Category': 'category', \n",
    "        'Line': 'line of code', \n",
    "        'classification': 'classification', \n",
    "        'File Name': 'file', \n",
    "        'Issue Type': 'type',\n",
    "        'Description': 'description'\n",
    "}\n",
    "\n",
    "codeql_columns = {\n",
    "        'scanner': 'scanner', \n",
    "        'cwe_id':'cwe', \n",
    "        'start_line': 'line of code', \n",
    "        'rule_name':'type', \n",
    "        'file_name': 'file',\n",
    "        'classification': 'classification', \n",
    "        'message': 'description'\n",
    "}\n",
    "\n",
    "checkov_columns = {\n",
    "        'scanner': 'scanner', \n",
    "        'line range': 'line of code', \n",
    "        'file_path': 'file',\n",
    "        'classification': 'classification', \n",
    "        'check_name': 'description',\n",
    "        'check_id': 'type'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkov_mnestix_results.rename(columns=checkov_columns, inplace=True)\n",
    "codeql_mnestix_results.rename(columns=codeql_columns, inplace=True)\n",
    "kics_mnestix_results.rename(columns=kics_columns, inplace=True)\n",
    "semgrep_mnestix_results.rename(columns=semgrep_columns, inplace=True)\n",
    "spotbugs_aas_env_results.rename(columns=spotbugs_columns, inplace=True)\n",
    "spotbugs_basyx_components_results.rename(columns=spotbugs_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in relevant_columns:\n",
    "  if col not in checkov_mnestix_results.columns:\n",
    "    checkov_mnestix_results[col] = None\n",
    "  if col not in codeql_mnestix_results.columns:\n",
    "    codeql_mnestix_results[col] = None\n",
    "  if col not in kics_mnestix_results.columns:\n",
    "    kics_mnestix_results[col] = None\n",
    "  if col not in semgrep_mnestix_results.columns:\n",
    "    semgrep_mnestix_results[col] = None\n",
    "  if col not in spotbugs_aas_env_results.columns:\n",
    "    spotbugs_aas_env_results[col] = None\n",
    "  if col not in spotbugs_basyx_components_results.columns:\n",
    "    spotbugs_basyx_components_results[col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkov = checkov_mnestix_results[relevant_columns]\n",
    "df_codeql = codeql_mnestix_results[relevant_columns]\n",
    "df_kics = kics_mnestix_results[relevant_columns]\n",
    "df_semgrep = semgrep_mnestix_results[relevant_columns]\n",
    "df_soptbugs_aas_env_results = spotbugs_aas_env_results[relevant_columns]\n",
    "df_soptbugs_basyx_copmponents_results = spotbugs_basyx_components_results[relevant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_checkov, df_codeql, df_kics, df_semgrep, df_soptbugs_aas_env_results, df_soptbugs_basyx_copmponents_results], ignore_index=True)\n",
    "combined_df['findings_id'] = combined_df.index.astype(str)\n",
    "combined_df['real vulnerability'] = combined_df['classification'].apply(lambda x: True if x == 'TP' else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_RESULTS_PATH = 'results/mnestix/model_results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qwen2.5 32B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_THRESHOLD_QWEN25_32B = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_qwen25_32b_sc_1 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.24_11-22-50_114.json\"\n",
    "filename_qwen25_32b_sc_2 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.24_11-47-10_114.json\"\n",
    "filename_qwen25_32b_sc_3 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.25_15-42-54_114.json\"\n",
    "filename_qwen25_32b_sc_4 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.25_16-24-15_114.json\"\n",
    "filename_qwen25_32b_sc_5 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.25_22-33-05_114.json\"\n",
    "\n",
    "files_to_load_mnestix_sc_qwen = (\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_1), \"Qwen2.5 32B sc1\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_2), \"Qwen2.5 32B sc2\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_3), \"Qwen2.5 32B sc3\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_4), \"Qwen2.5 32B sc4\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_5), \"Qwen2.5 32B sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_mnestix_sc_qwen:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"findings_id\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(combined_df[\"findings_id\"], combined_df[\"real vulnerability\"]))\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"findings_id\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= MNESTIX_THRESHOLD_QWEN25_32B) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Qwen2.5 32B SC results on MNESTIX dataset\n",
      "TP    49\n",
      "FP    46\n",
      "TN    19\n",
      "FN     0\n",
      "Name: llm_classification, dtype: int64\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Qwen2.5 32B SC results on MNESTIX dataset\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))\n",
    "\n",
    "labeled_sc_df_qwen25_32b = df_sc_consistent.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phi-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_PHI4_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_phi_sc_1 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_15-17-48_114.json\"\n",
    "filename_phi_sc_2 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_16-59-12_114.json\"\n",
    "filename_phi_sc_3 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_19-10-57_114.json\"\n",
    "filename_phi_sc_4 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_23-06-49_114.json\"\n",
    "filename_phi_sc_5 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.25_14-41-29_114.json\"\n",
    "\n",
    "files_to_load_sc_phi4 = (\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_1), \"phi_4 sc1\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_2), \"phi_4 sc2\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_3), \"phi_4 sc3\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_4), \"phi_4 sc4\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_5), \"phi_4 sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_sc_phi4:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"findings_id\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(combined_df[\"findings_id\"], combined_df[\"real vulnerability\"]))\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"findings_id\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= MNESTIX_PHI4_THRESHOLD) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Phi-4 SC results on MNESTIX dataset\n",
      "TP    49\n",
      "FP    43\n",
      "TN    22\n",
      "FN     0\n",
      "Name: llm_classification, dtype: int64\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Phi-4 SC results on MNESTIX dataset\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))\n",
    "\n",
    "labeled_sc_df_phi4 = df_sc_consistent.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_GPT4O_THRESHOLD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_gpt4o_sc_1 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_23-34-18_114.json\"\n",
    "filename_gpt4o_sc_2 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.01_00-09-04_114.json\"\n",
    "filename_gpt4o_sc_3 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.01_00-33-19_114.json\"\n",
    "filename_gpt4o_sc_4 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.01_13-15-25_114.json\"\n",
    "filename_gpt4o_sc_5 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.10_16-56-32_114.json\"\n",
    "\n",
    "files_to_load_sc_gpt4o = (\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_1), \"GPT-4o sc1\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_2), \"GPT-4o sc2\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_3), \"GPT-4o sc3\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_4), \"GPT-4o sc4\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_5), \"GPT-4o sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_sc_gpt4o:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"findings_id\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(combined_df[\"findings_id\"], combined_df[\"real vulnerability\"]))\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"findings_id\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= MNESTIX_GPT4O_THRESHOLD) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for GPT-4o SC results on MNESTIX dataset\n",
      "TP    48\n",
      "FP    49\n",
      "TN    16\n",
      "FN     1\n",
      "Name: llm_classification, dtype: int64\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for GPT-4o SC results on MNESTIX dataset\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))\n",
    "\n",
    "labeled_sc_df_gpt4o = df_sc_consistent.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining model results of conservative analysis (Phi-4 and Qwen2.5 32B) on Mnestix dataset:\n",
      "TP    49\n",
      "FP    40\n",
      "TN    25\n",
      "FN     0\n",
      "Name: llm_classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# hypthetically combining of QWEN2.5 32B and Phi-4 results due to their conservative analysis on the Mnestix dataset\n",
    "df_qwen = labeled_sc_df_qwen25_32b[['findings_id', 'llm_vul_decision', 'real_vulnerability']].rename(columns={'llm_vul_decision': 'qwen_decision'})\n",
    "df_phi = labeled_sc_df_phi4[['findings_id', 'llm_vul_decision']].rename(columns={'llm_vul_decision': 'phi_decision'})\n",
    "\n",
    "vote_df = df_qwen.merge(df_phi, on='findings_id')\n",
    "vote_df['consensus_decision'] = vote_df[['qwen_decision', 'phi_decision']].sum(axis=1) >= 2\n",
    "\n",
    "conditions = [\n",
    "  (vote_df['real_vulnerability'] == True) & (vote_df['consensus_decision'] == True),\n",
    "  (vote_df['real_vulnerability'] == False) & (vote_df['consensus_decision'] == True),\n",
    "  (vote_df['real_vulnerability'] == False) & (vote_df['consensus_decision'] == False),\n",
    "  (vote_df['real_vulnerability'] == True) & (vote_df['consensus_decision'] == False)\n",
    "]\n",
    "choices = ['TP', 'FP', 'TN', 'FN']\n",
    "\n",
    "vote_df['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "classification_counts = vote_df['llm_classification'].value_counts().reindex(['TP', 'FP', 'TN', 'FN'], fill_value=0)\n",
    "print(\"Combining model results of conservative analysis (Phi-4 and Qwen2.5 32B) on Mnestix dataset:\")\n",
    "print(classification_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
