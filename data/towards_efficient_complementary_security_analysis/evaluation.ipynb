{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPOTBUGS_DATASET_PATH = '../owasp_benchmark/spotbugs_dataset.pkl'\n",
    "spotbugs_dataset = pd.read_pickle(SPOTBUGS_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_gemini_1_0 = \"experiment_3_config2__few_shot_CoT__gemini-1.0-pro-002_2024.07.01_10-30-08_403.json\"\n",
    "filename_gemini_1_5 = \"experiment_3_config2__few_shot_CoT__gemini-1.5-pro-001_2024.07.01_14-56-04_403.json\"\n",
    "filename_llama3_8b = \"experiment_3_config2__few_shot_CoT__meta-llama-Meta-Llama-3-8B-Instruct_2024.07.05_18-10-14_403.json\"\n",
    "filename_llama3_70b = \"experiment_3_config2__few_shot_CoT__meta-llama-Meta-Llama-3-70B-Instruct-Q4_K_M.gguf_2024.07.15_15-13-02_403.json\"\n",
    "filename_llama31_70b = \"experiment_3_config2__few_shot_CoT__hugging-quants-Meta-Llama-3.1-70B-Instruct-AWQ-INT4_2024.07.26_00-52-40_403.json\"\n",
    "filename_gpt4o = \"experiment_3_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.06.19_00-54-42_403.json\"\n",
    "filename_gpt35_turbo = \"experiment_3_config2__few_shot_CoT__gpt-35-turbo_2024.06.24_13-52-02_403.json\"\n",
    "filename_phi3_medium = \"experiment_3_config2__few_shot_CoT__microsoft-Phi-3-medium-128k-instruct_2024.07.11_23-48-57_403.json\"\n",
    "filename_phi4 = \"experiment_3_config2__few_shot_CoT__microsoft-phi-4_2025.01.20_17-53-56_403.json\"\n",
    "filename_qwen15_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-7B-Chat_2025.01.04_16-12-46_403.json\"\n",
    "filename_qwen15_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-14B-Chat-GPTQ-Int4_2025.01.04_19-17-19_403.json\"\n",
    "filename_qwen15_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-14B-Chat-GPTQ-Int4_2025.01.04_19-17-19_403.json\"\n",
    "filename_qwen15_32b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-32B-Chat-GPTQ-Int4_2025.01.04_18-10-00_403.json\"\n",
    "filename_qwen2_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2-7B-Instruct_2025.01.04_00-28-55_403.json\"\n",
    "filename_qwen2_72b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2-72B-Instruct-GPTQ-Int4_2025.01.20_15-37-51_403.json\"\n",
    "filename_qwen25_05b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-0.5B-Instruct_2024.12.30_18-19-37_403.json\"\n",
    "filename_qwen25_1b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-1.5B-Instruct_2024.12.30_18-02-42_403.json\"\n",
    "filename_qwen25_3b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-3B-Instruct_2024.12.30_15-16-53_403.json\"\n",
    "filename_qwen25_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-7B-Instruct_2024.12.30_13-52-47_403.json\"\n",
    "filename_qwen25_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-14B-Instruct-GPTQ-Int4_2024.12.30_19-26-54_403.json\"\n",
    "filename_qwen25_32b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2024.12.31_00-11-19_403.json\"\n",
    "filename_qwen25_72b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-72B-Instruct-GPTQ-Int8_2025.01.25_17-59-59_403.json\"\n",
    "filename_qwen25_coder_05b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-0.5B-Instruct_2025.01.03_16-12-41_403.json\"\n",
    "filename_qwen25_coder_1b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-1.5B-Instruct_2025.01.03_16-34-53_403.json\"\n",
    "filename_qwen25_coder_3b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-3B-Instruct_2025.01.03_17-13-41_403.json\"\n",
    "filename_qwen25_coder_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-7B-Instruct_2025.01.03_18-51-15_403.json\"\n",
    "filename_qwen25_coder_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-14B-Instruct-GPTQ-Int4_2025.01.03_21-02-19_403.json\"\n",
    "filename_qwen25_coder_32b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-32B-Instruct-GPTQ-Int4_2025.01.03_23-18-16_403.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load = (\n",
    "    (os.path.join(RESULTS_PATH, filename_gemini_1_0), \"gemini_1_0\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_gemini_1_5), \"gemini_1_5\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_llama3_8b), \"llama3_8b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_llama3_70b), \"llama3_70b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_llama31_70b), \"llama31_70b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_gpt4o), \"gpt_4o\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_gpt35_turbo), \"gpt35_turbo\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_phi3_medium), \"phi3_medium\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_phi4), \"phi_4\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen15_7b), \"qwen15_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen15_14b), \"qwen15_14b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen15_32b), \"qwen15_32b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen2_7b), \"qwen2_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen2_72b), \"qwen2_72b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_05b), \"qwen2.5_05b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_1b), \"qwen2.5_1b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_3b), \"qwen2.5_3b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_7b), \"qwen2.5_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_14b), \"qwen2.5_14b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_32b), \"qwen2.5_32b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_72b), \"qwen2.5_72b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_05b), \"qwen2.5_coder_05b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_1b), \"qwen2.5_coder_1b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_3b), \"qwen2.5_coder_3b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_7b), \"qwen2.5_coder_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_14b), \"qwen2.5_coder_14b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_32b), \"qwen2.5_coder_32b\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "for file_path, df_name in files_to_load:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD = 2\n",
    "choices = ['TP', 'FP', 'TN', 'FN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for gemini_1_0 on OWASP Benchmark test split:\n",
      "TP    269\n",
      "FP    113\n",
      "TN     15\n",
      "FN      6\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for gemini_1_5 on OWASP Benchmark test split:\n",
      "TP    266\n",
      "FP     28\n",
      "TN    100\n",
      "FN      9\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for llama3_8b on OWASP Benchmark test split:\n",
      "TP    274\n",
      "FP    119\n",
      "TN      9\n",
      "FN      1\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for llama3_70b on OWASP Benchmark test split:\n",
      "TP    269\n",
      "FP     74\n",
      "TN     54\n",
      "FN      6\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for llama31_70b on OWASP Benchmark test split:\n",
      "TP    251\n",
      "FP     16\n",
      "TN    112\n",
      "FN     24\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for gpt_4o on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP     78\n",
      "TN     50\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for gpt35_turbo on OWASP Benchmark test split:\n",
      "TP    271\n",
      "FP    113\n",
      "TN     15\n",
      "FN      4\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for phi3_medium on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP    112\n",
      "TN     16\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for phi_4 on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP     52\n",
      "TN     76\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen15_7b on OWASP Benchmark test split:\n",
      "TP    272\n",
      "FP    127\n",
      "TN      1\n",
      "FN      3\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen15_14b on OWASP Benchmark test split:\n",
      "TP    259\n",
      "FP    106\n",
      "TN     22\n",
      "FN     16\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen15_32b on OWASP Benchmark test split:\n",
      "TP    263\n",
      "FP     95\n",
      "TN     33\n",
      "FN     12\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2_7b on OWASP Benchmark test split:\n",
      "TP    268\n",
      "FP    104\n",
      "TN     24\n",
      "FN      7\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2_72b on OWASP Benchmark test split:\n",
      "TP    274\n",
      "FP     83\n",
      "TN     45\n",
      "FN      1\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_05b on OWASP Benchmark test split:\n",
      "TP    233\n",
      "FP    112\n",
      "TN     16\n",
      "FN     42\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_1b on OWASP Benchmark test split:\n",
      "TP    266\n",
      "FP    119\n",
      "TN      9\n",
      "FN      9\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_3b on OWASP Benchmark test split:\n",
      "TP    268\n",
      "FP    116\n",
      "TN     12\n",
      "FN      7\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_7b on OWASP Benchmark test split:\n",
      "TP    269\n",
      "FP    118\n",
      "TN     10\n",
      "FN      6\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_14b on OWASP Benchmark test split:\n",
      "TP    272\n",
      "FP     51\n",
      "TN     77\n",
      "FN      3\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_32b on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP     57\n",
      "TN     71\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_72b on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP     80\n",
      "TN     48\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_05b on OWASP Benchmark test split:\n",
      "TP    275\n",
      "FP    128\n",
      "TN      0\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_1b on OWASP Benchmark test split:\n",
      "TP    266\n",
      "FP    126\n",
      "TN      2\n",
      "FN      9\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_3b on OWASP Benchmark test split:\n",
      "TP    268\n",
      "FP    123\n",
      "TN      5\n",
      "FN      7\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_7b on OWASP Benchmark test split:\n",
      "TP    274\n",
      "FP    122\n",
      "TN      6\n",
      "FN      1\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_14b on OWASP Benchmark test split:\n",
      "TP    269\n",
      "FP     72\n",
      "TN     56\n",
      "FN      6\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_32b on OWASP Benchmark test split:\n",
      "TP    273\n",
      "FP     59\n",
      "TN     69\n",
      "FN      2\n",
      "Name: llm_classification, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dataframes.values():\n",
    "    df[\"llm_vul_decision\"] = np.where(df[\"threshold_value\"] < 0.0, True, df[\"threshold_value\"] >= TRESHOLD)\n",
    "    \n",
    "    conditions = [\n",
    "        (df[\"real_vulnerability\"] == True) & (df[\"llm_vul_decision\"] == True),\n",
    "        (df[\"real_vulnerability\"] == False) & (df[\"llm_vul_decision\"] == True),\n",
    "        (df[\"real_vulnerability\"] == False) & (df[\"llm_vul_decision\"] == False),\n",
    "        (df[\"real_vulnerability\"] == True) & (df[\"llm_vul_decision\"] == False)\n",
    "    ]\n",
    "    df[\"llm_classification\"] = np.select(conditions, choices)\n",
    "\n",
    "for model, df in dataframes.items():\n",
    "    print(f\"Confusion Matrix for {model} on OWASP Benchmark test split:\")\n",
    "    print(df[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_RESULTS_PATH = 'self_consistency_results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_phi4_sc1 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.20_17-53-56_403.json\"\n",
    "filename_phi4_sc2 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.21_23-09-57_403.json\"\n",
    "filename_phi4_sc3 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.22_11-03-37_403.json\"\n",
    "filename_phi4_sc4 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.22_12-48-26_403.json\"\n",
    "filename_phi4_sc5 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.22_14-03-20_403.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load_sc_phi4 = (\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc1), \"phi_4 sc1\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc2), \"phi_4 sc2\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc3), \"phi_4 sc3\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc4), \"phi_4 sc4\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc5), \"phi_4 sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_sc_phi4:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD_PHI_4 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= TRESHOLD) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Phi4 SC results on OWASP Benchmark test split\n",
      "TP    275\n",
      "FP     52\n",
      "TN     76\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Phi4 SC results on OWASP Benchmark test split\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qwen 2.5 32B Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_qwen_sc1 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.23_17-22-31_403.json\"\n",
    "filename_qwen_sc2 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.23_23-18-22_403.json\"\n",
    "filename_qwen_sc3 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.24_13-24-46_403.json\"\n",
    "filename_qwen_sc4 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.24_18-09-55_403.json\"\n",
    "filename_qwen_sc5 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2024.12.31_00-11-19_403.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load_sc_qwen25_32b = (\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc1), \"Qwen2.5 sc1\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc2), \"Qwen2.5 sc2\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc3), \"Qwen2.5 sc3\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc4), \"Qwen2.5 sc4\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc5), \"Qwen2.5 sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc_qwen = {}\n",
    "for file_path, df_name in files_to_load_sc_qwen25_32b:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc_qwen[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes_sc_qwen.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD_QWEN25_32B = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Qwen2.5 32B SC results on  OWASP Benchmark test split\n",
      "TP    275\n",
      "FP     48\n",
      "TN     80\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "for _, df in dataframes_sc_qwen.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= TRESHOLD_QWEN25_32B) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent_qwen = list(dataframes_sc_qwen.values())[0].copy()\n",
    "dfs_qwen = list(dataframes_sc_qwen.values())\n",
    "dfs_other = [df for df in dfs_qwen if df is not list(dataframes_sc_qwen.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent_qwen.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs_qwen]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent_qwen.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent_qwen.at[idx, 'llm_vul_decision'] = consensus\n",
    "\n",
    "for _, _ in dataframes_sc_qwen.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == True) & (df_sc_consistent_qwen['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == False) & (df_sc_consistent_qwen['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == False) & (df_sc_consistent_qwen['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == True) & (df_sc_consistent_qwen['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent_qwen['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Qwen2.5 32B SC results on  OWASP Benchmark test split\")\n",
    "print(df_sc_consistent_qwen[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent_qwen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_gpt4o_sc1 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.06.19_00-54-42_403.json\"\n",
    "filename_gpt4o_sc2 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_15-43-27_403.json\"\n",
    "filename_gpt4o_sc3 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_17-49-47_403.json\"\n",
    "filename_gpt4o_sc4 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_18-52-38_403.json\"\n",
    "filename_gpt4o_sc5 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.07_23-14-22_403.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load_sc_gpt4o = (\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc1), \"GPT-4o sc1\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc2), \"GPT-4o sc2\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc3), \"GPT-4o sc3\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc4), \"GPT-4o sc4\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc5), \"GPT-4o sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc_gpt4o = {}\n",
    "for file_path, df_name in files_to_load_sc_gpt4o:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc_gpt4o[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes_sc_gpt4o.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD_GPT4O = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for GPT-4o SC results on  OWASP Benchmark test split\n",
      "TP    275\n",
      "FP     48\n",
      "TN     80\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "for _, df in dataframes_sc_gpt4o.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= TRESHOLD_GPT4O) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent_gpt4o = list(dataframes_sc_gpt4o.values())[0].copy()\n",
    "dfs_gpt4o = list(dataframes_sc_gpt4o.values())\n",
    "dfs_other = [df for df in dfs_gpt4o if df is not list(dataframes_sc_gpt4o.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent_gpt4o.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs_gpt4o]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent_gpt4o.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent_gpt4o.at[idx, 'llm_vul_decision'] = consensus\n",
    "\n",
    "for _, _ in dataframes_sc_gpt4o.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == True) & (df_sc_consistent_gpt4o['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == False) & (df_sc_consistent_gpt4o['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == False) & (df_sc_consistent_gpt4o['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == True) & (df_sc_consistent_gpt4o['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent_gpt4o['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for GPT-4o SC results on  OWASP Benchmark test split\")\n",
    "print(df_sc_consistent_gpt4o[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent_gpt4o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnestix (Real-World Dataset)\n",
    "\n",
    "To demonstrate that our approach is not only effective on benchmark datasets but also applicable to real-world security analysis, we applied it to the open-source project Mnestix, developed by XITASO GmbH. This analysis allowed us to validate our approach on real-world software weaknesses while ensuring transparency in discussing the findings.\n",
    "\n",
    "We utilized multiple SAST tools to analyze the Mnestix codebase, which includes components written in C#, TypeScript, and infrastructure code, as well as BASXY, an open-source Java codebase. The selected tools—CodeQL, Semgrep, SpotBugs with FindSecBugs, Checkov, and KICS—enabled us to cover a broad range of security weaknesses across different programming paradigms. The findings from these SAST tools were manually labeled by security experts and then assessed by the previously identified best-performing LLMs for our specific use case: GPT-4o, Qwen2.5-32B, and Phi-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNESTIX Results\n",
    "CHECKOV_MNESTIX_RESULTS_FILE_PATH = \"mnestix/tool_results/checkov_labeled_results.xlsx\"\n",
    "CODEQL_MNESTIX_RESULTS_FILE_PATH = \"mnestix/tool_results/code_ql_labeled_results.xlsx\"\n",
    "KICS_MNESTIX_RESULTS_FILE_PATH = \"mnestix/tool_results/kics_labled_results.xlsx\"\n",
    "SEMGREP_MNESTIX_RESULTS_FILE_PATH = \"mnestix/tool_results/semgrep_labeled_results.xlsx\"\n",
    "\n",
    "#BASYX Results\n",
    "SPOTBUGS_AAS_ENV_RESULTS_FILE_PATH = \"mnestix/tool_results/spotbugs_aas_env_labeled_report.xlsx\"\n",
    "SPOTBUGS_BASYX_COMPONENTS_RESULTS_FILE_PATH = \"mnestix/tool_results/spotbugs_basyx_labeled_report.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkov_mnestix_results = pd.read_excel(CHECKOV_MNESTIX_RESULTS_FILE_PATH)\n",
    "checkov_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "codeql_mnestix_results = pd.read_excel(CODEQL_MNESTIX_RESULTS_FILE_PATH)\n",
    "codeql_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "kics_mnestix_results = pd.read_excel(KICS_MNESTIX_RESULTS_FILE_PATH)\n",
    "kics_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "semgrep_mnestix_results = pd.read_excel(SEMGREP_MNESTIX_RESULTS_FILE_PATH)\n",
    "semgrep_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "spotbugs_aas_env_results = pd.read_excel(SPOTBUGS_AAS_ENV_RESULTS_FILE_PATH)\n",
    "spotbugs_aas_env_results.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to every SAST scanner having different column names, we need to map them to a common set of column names\n",
    "relevant_columns = ['scanner', 'category', 'cwe', 'line of code', 'type', 'method', 'file', 'description', 'classification']\n",
    "\n",
    "spotbugs_columns = {\n",
    "    'scanner': 'scanner', \n",
    "    'type': 'type', \n",
    "    'cweid': 'cwe', \n",
    "    'category': 'category', \n",
    "    'method': 'method', \n",
    "    'sourceLine': 'line of code', \n",
    "    'classification': 'classification', \n",
    "    'sourceFile': 'file'\n",
    "}\n",
    "\n",
    "semgrep_columns = {\n",
    "    'scanner': 'scanner', \n",
    "    'cwe_id': 'cwe', \n",
    "    'category': 'category', \n",
    "    'start_line': 'line of code', \n",
    "    'classification': 'classification', \n",
    "    'path': 'file', \n",
    "    'message': 'description',\n",
    "    'type': 'type'\n",
    "}\n",
    "\n",
    "kics_columns = {\n",
    "        'scanner': 'scanner', \n",
    "        'Category': 'category', \n",
    "        'Line': 'line of code', \n",
    "        'classification': 'classification', \n",
    "        'File Name': 'file', \n",
    "        'Issue Type': 'type',\n",
    "        'Description': 'description'\n",
    "}\n",
    "\n",
    "codeql_columns = {\n",
    "        'scanner': 'scanner', \n",
    "        'cwe_id':'cwe', \n",
    "        'start_line': 'line of code', \n",
    "        'rule_name':'type', \n",
    "        'file_name': 'file',\n",
    "        'classification': 'classification', \n",
    "        'message': 'description'\n",
    "}\n",
    "\n",
    "checkov_columns = {\n",
    "        'scanner': 'scanner', \n",
    "        'line range': 'line of code', \n",
    "        'file_path': 'file',\n",
    "        'classification': 'classification', \n",
    "        'check_name': 'description',\n",
    "        'check_id': 'type'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkov_mnestix_results.rename(columns=checkov_columns, inplace=True)\n",
    "codeql_mnestix_results.rename(columns=codeql_columns, inplace=True)\n",
    "kics_mnestix_results.rename(columns=kics_columns, inplace=True)\n",
    "semgrep_mnestix_results.rename(columns=semgrep_columns, inplace=True)\n",
    "spotbugs_aas_env_results.rename(columns=spotbugs_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in relevant_columns:\n",
    "  if col not in checkov_mnestix_results.columns:\n",
    "    checkov_mnestix_results[col] = None\n",
    "  if col not in codeql_mnestix_results.columns:\n",
    "    codeql_mnestix_results[col] = None\n",
    "  if col not in kics_mnestix_results.columns:\n",
    "    kics_mnestix_results[col] = None\n",
    "  if col not in semgrep_mnestix_results.columns:\n",
    "    semgrep_mnestix_results[col] = None\n",
    "  if col not in spotbugs_aas_env_results.columns:\n",
    "    spotbugs_aas_env_results[col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkov = checkov_mnestix_results[relevant_columns]\n",
    "df_codeql = codeql_mnestix_results[relevant_columns]\n",
    "df_kics = kics_mnestix_results[relevant_columns]\n",
    "df_semgrep = semgrep_mnestix_results[relevant_columns]\n",
    "df_soptbugs_aas_env_results = spotbugs_aas_env_results[relevant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_checkov, df_codeql, df_kics, df_semgrep, df_soptbugs_aas_env_results], ignore_index=True)\n",
    "combined_df['findings_id'] = combined_df.index.astype(str)\n",
    "combined_df['real vulnerability'] = combined_df['classification'].apply(lambda x: True if x == 'TP' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df) #6 samples will be exluded as they were used for few-shot example generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_scanner_counts = combined_df.groupby(['scanner', 'type']).size().reset_index(name='count')\n",
    "filtered_df = combined_df[~combined_df['findings_id'].isin([\"107\", \"114\", \"119\", \"4\", \"65\", \"53\"])] #exlucde few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scanner</th>\n",
       "      <th>type</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Checkov</td>\n",
       "      <td>CKV_DOCKER_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Checkov</td>\n",
       "      <td>CKV_DOCKER_3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Checkov</td>\n",
       "      <td>CKV_SECRET_4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Checkov</td>\n",
       "      <td>CKV_SECRET_6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CodeQL</td>\n",
       "      <td>cs/log-forging</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CodeQL</td>\n",
       "      <td>js/overly-large-range</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KICS</td>\n",
       "      <td>IncorrectValue</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KICS</td>\n",
       "      <td>MissingAttribute</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KICS</td>\n",
       "      <td>RedundantAttribute</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Semgrep</td>\n",
       "      <td>Inefficient-Regular-Expression-Complexity</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SpotBugs w/ FindSecBugs</td>\n",
       "      <td>BC_VACUOUS_INSTANCEOF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SpotBugs w/ FindSecBugs</td>\n",
       "      <td>EI_EXPOSE_REP</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SpotBugs w/ FindSecBugs</td>\n",
       "      <td>EI_EXPOSE_REP2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     scanner                                        type  TP  \\\n",
       "0                    Checkov                                CKV_DOCKER_2   0   \n",
       "1                    Checkov                                CKV_DOCKER_3   0   \n",
       "2                    Checkov                                CKV_SECRET_4   2   \n",
       "3                    Checkov                                CKV_SECRET_6   4   \n",
       "4                     CodeQL                              cs/log-forging  34   \n",
       "5                     CodeQL                       js/overly-large-range   0   \n",
       "6                       KICS                              IncorrectValue   1   \n",
       "7                       KICS                            MissingAttribute   4   \n",
       "8                       KICS                          RedundantAttribute   4   \n",
       "9                    Semgrep   Inefficient-Regular-Expression-Complexity   0   \n",
       "10  SpotBugs w/ FindSecBugs                        BC_VACUOUS_INSTANCEOF   0   \n",
       "11  SpotBugs w/ FindSecBugs                                EI_EXPOSE_REP   0   \n",
       "12  SpotBugs w/ FindSecBugs                               EI_EXPOSE_REP2   0   \n",
       "\n",
       "    FP  Total  \n",
       "0    2      2  \n",
       "1    2      2  \n",
       "2    2      4  \n",
       "3    3      7  \n",
       "4    1     35  \n",
       "5    2      2  \n",
       "6    8      9  \n",
       "7   18     22  \n",
       "8    4      8  \n",
       "9    3      3  \n",
       "10   1      1  \n",
       "11   6      6  \n",
       "12  13     13  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_scanner_counts = filtered_df.groupby(['scanner', 'type']).size().reset_index(name='count')\n",
    "type_scanner_counts = type_scanner_counts.rename(columns={'count': 'Total'})\n",
    "\n",
    "tp_counts = filtered_df[filtered_df['classification'] == 'TP'].groupby(['scanner', 'type']).size().reset_index(name='TP')\n",
    "fp_counts = filtered_df[filtered_df['classification'] == 'FP'].groupby(['scanner', 'type']).size().reset_index(name='FP')\n",
    "\n",
    "type_scanner_counts = type_scanner_counts.merge(tp_counts, on=['scanner', 'type'], how='left') \\\n",
    "                     .merge(fp_counts, on=['scanner', 'type'], how='left')\n",
    "type_scanner_counts = type_scanner_counts[['scanner', 'type', 'TP', 'FP', 'Total']]\n",
    "\n",
    "type_scanner_counts[['TP', 'FP']] = type_scanner_counts[['TP', 'FP']].fillna(0).astype(int)\n",
    "type_scanner_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_RESULTS_PATH = 'mnestix/model_results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qwen2.5 32B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_THRESHOLD_QWEN25_32B = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_qwen25_32b_sc_1 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.24_11-22-50_114.json\"\n",
    "filename_qwen25_32b_sc_2 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.24_11-47-10_114.json\"\n",
    "filename_qwen25_32b_sc_3 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.25_15-42-54_114.json\"\n",
    "filename_qwen25_32b_sc_4 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.25_16-24-15_114.json\"\n",
    "filename_qwen25_32b_sc_5 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.25_22-33-05_114.json\"\n",
    "\n",
    "files_to_load_mnestix_sc_qwen = (\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_1), \"Qwen2.5 32B sc1\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_2), \"Qwen2.5 32B sc2\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_3), \"Qwen2.5 32B sc3\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_4), \"Qwen2.5 32B sc4\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_5), \"Qwen2.5 32B sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_mnestix_sc_qwen:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"findings_id\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(combined_df[\"findings_id\"], combined_df[\"real vulnerability\"]))\n",
    "real_vulnerability_map.update({'120': False, '121': False, '122': False})\n",
    "\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"findings_id\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= MNESTIX_THRESHOLD_QWEN25_32B) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Qwen2.5 32B SC results on Mnestix dataset\n",
      "TP    49\n",
      "FP    46\n",
      "TN    19\n",
      "FN     0\n",
      "Name: llm_classification, dtype: int64\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Qwen2.5 32B SC results on Mnestix dataset\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))\n",
    "\n",
    "labeled_sc_df_qwen25_32b = df_sc_consistent.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phi-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_PHI4_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_phi_sc_1 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_15-17-48_114.json\"\n",
    "filename_phi_sc_2 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_16-59-12_114.json\"\n",
    "filename_phi_sc_3 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_19-10-57_114.json\"\n",
    "filename_phi_sc_4 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_23-06-49_114.json\"\n",
    "filename_phi_sc_5 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.25_14-41-29_114.json\"\n",
    "\n",
    "files_to_load_sc_phi4 = (\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_1), \"phi_4 sc1\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_2), \"phi_4 sc2\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_3), \"phi_4 sc3\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_4), \"phi_4 sc4\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_5), \"phi_4 sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_sc_phi4:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"findings_id\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(combined_df[\"findings_id\"], combined_df[\"real vulnerability\"]))\n",
    "real_vulnerability_map.update({'120': False, '121': False, '122': False})\n",
    "\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"findings_id\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= MNESTIX_PHI4_THRESHOLD) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Phi-4 SC results on MNESTIX dataset\n",
      "TP    49\n",
      "FP    43\n",
      "TN    22\n",
      "FN     0\n",
      "Name: llm_classification, dtype: int64\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Phi-4 SC results on MNESTIX dataset\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))\n",
    "\n",
    "labeled_sc_df_phi4 = df_sc_consistent.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_GPT4O_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_gpt4o_sc_1 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_23-34-18_114.json\"\n",
    "filename_gpt4o_sc_2 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.01_00-09-04_114.json\"\n",
    "filename_gpt4o_sc_3 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.01_00-33-19_114.json\"\n",
    "filename_gpt4o_sc_4 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.01_13-15-25_114.json\"\n",
    "filename_gpt4o_sc_5 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.10_16-56-32_114.json\"\n",
    "\n",
    "files_to_load_sc_gpt4o = (\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_1), \"GPT-4o sc1\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_2), \"GPT-4o sc2\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_3), \"GPT-4o sc3\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_4), \"GPT-4o sc4\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_5), \"GPT-4o sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_sc_gpt4o:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"findings_id\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(combined_df[\"findings_id\"], combined_df[\"real vulnerability\"]))\n",
    "real_vulnerability_map.update({'120': False, '121': False, '122': False})\n",
    "\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"findings_id\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= MNESTIX_GPT4O_THRESHOLD) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for GPT-4o SC results on MNESTIX dataset\n",
      "TP    48\n",
      "FP    41\n",
      "TN    24\n",
      "FN     1\n",
      "Name: llm_classification, dtype: int64\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for GPT-4o SC results on MNESTIX dataset\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))\n",
    "\n",
    "labeled_sc_df_gpt4o = df_sc_consistent.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining model results of conservative analysis (Phi-4 and Qwen2.5 32B) on Mnestix dataset:\n",
      "TP    49\n",
      "FP    40\n",
      "TN    25\n",
      "FN     0\n",
      "Name: llm_classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# combining of QWEN2.5 32B and Phi-4 results due to their conservative analysis on the Mnestix dataset\n",
    "df_qwen = labeled_sc_df_qwen25_32b[['findings_id', 'llm_vul_decision', 'real_vulnerability']].rename(columns={'llm_vul_decision': 'qwen_decision'})\n",
    "df_phi = labeled_sc_df_phi4[['findings_id', 'llm_vul_decision']].rename(columns={'llm_vul_decision': 'phi_decision'})\n",
    "\n",
    "vote_df = df_qwen.merge(df_phi, on='findings_id')\n",
    "vote_df['consensus_decision'] = vote_df[['qwen_decision', 'phi_decision']].sum(axis=1) >= 2\n",
    "\n",
    "conditions = [\n",
    "  (vote_df['real_vulnerability'] == True) & (vote_df['consensus_decision'] == True),\n",
    "  (vote_df['real_vulnerability'] == False) & (vote_df['consensus_decision'] == True),\n",
    "  (vote_df['real_vulnerability'] == False) & (vote_df['consensus_decision'] == False),\n",
    "  (vote_df['real_vulnerability'] == True) & (vote_df['consensus_decision'] == False)\n",
    "]\n",
    "choices = ['TP', 'FP', 'TN', 'FN']\n",
    "\n",
    "vote_df['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "classification_counts = vote_df['llm_classification'].value_counts().reindex(['TP', 'FP', 'TN', 'FN'], fill_value=0)\n",
    "print(\"Combining model results of conservative analysis (Phi-4 and Qwen2.5 32B) on Mnestix dataset:\")\n",
    "print(classification_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
