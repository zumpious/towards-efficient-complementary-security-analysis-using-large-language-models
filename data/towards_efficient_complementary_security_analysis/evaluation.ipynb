{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPOTBUGS_DATASET_PATH = '../owasp_benchmark/spotbugs_dataset.pkl'\n",
    "spotbugs_dataset = pd.read_pickle(SPOTBUGS_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_gemini_1_0 = \"experiment_3_config2__few_shot_CoT__gemini-1.0-pro-002_2024.07.01_10-30-08_403.json\"\n",
    "filename_gemini_1_5 = \"experiment_3_config2__few_shot_CoT__gemini-1.5-pro-001_2024.07.01_14-56-04_403.json\"\n",
    "filename_llama3_8b = \"experiment_3_config2__few_shot_CoT__meta-llama-Meta-Llama-3-8B-Instruct_2024.07.05_18-10-14_403.json\"\n",
    "filename_llama31_70b = \"experiment_3_config2__few_shot_CoT__hugging-quants-Meta-Llama-3.1-70B-Instruct-AWQ-INT4_2024.07.26_00-52-40_403.json\"\n",
    "filename_gpt4o = \"experiment_3_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.06.19_00-54-42_403.json\"\n",
    "filename_gpt35_turbo = \"experiment_3_config2__few_shot_CoT__gpt-35-turbo_2024.06.24_13-52-02_403.json\"\n",
    "filename_phi3_medium = \"experiment_3_config2__few_shot_CoT__microsoft-Phi-3-medium-128k-instruct_2024.07.11_23-48-57_403.json\"\n",
    "filename_phi4 = \"experiment_3_config2__few_shot_CoT__microsoft-phi-4_2025.01.20_17-53-56_403.json\"\n",
    "filename_qwen15_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-7B-Chat_2025.01.04_16-12-46_403.json\"\n",
    "filename_qwen15_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-14B-Chat-GPTQ-Int4_2025.01.04_19-17-19_403.json\"\n",
    "filename_qwen15_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-14B-Chat-GPTQ-Int4_2025.01.04_19-17-19_403.json\"\n",
    "filename_qwen15_32b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen1.5-32B-Chat-GPTQ-Int4_2025.01.04_18-10-00_403.json\"\n",
    "filename_qwen2_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2-7B-Instruct_2025.01.04_00-28-55_403.json\"\n",
    "filename_qwen2_72b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2-72B-Instruct-GPTQ-Int4_2025.01.20_15-37-51_403.json\"\n",
    "filename_qwen25_05b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-0.5B-Instruct_2024.12.30_18-19-37_403.json\"\n",
    "filename_qwen25_1b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-1.5B-Instruct_2024.12.30_18-02-42_403.json\"\n",
    "filename_qwen25_3b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-3B-Instruct_2024.12.30_15-16-53_403.json\"\n",
    "filename_qwen25_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-7B-Instruct_2024.12.30_13-52-47_403.json\"\n",
    "filename_qwen25_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-14B-Instruct-GPTQ-Int4_2024.12.30_19-26-54_403.json\"\n",
    "filename_qwen25_32b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2024.12.31_00-11-19_403.json\"\n",
    "filename_qwen25_72b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-72B-Instruct-GPTQ-Int8_2025.01.25_17-59-59_403.json\"\n",
    "filename_qwen25_coder_05b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-0.5B-Instruct_2025.01.03_16-12-41_403.json\"\n",
    "filename_qwen25_coder_1b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-1.5B-Instruct_2025.01.03_16-34-53_403.json\"\n",
    "filename_qwen25_coder_3b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-3B-Instruct_2025.01.03_17-13-41_403.json\"\n",
    "filename_qwen25_coder_7b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-7B-Instruct_2025.01.03_18-51-15_403.json\"\n",
    "filename_qwen25_coder_14b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-14B-Instruct-GPTQ-Int4_2025.01.03_21-02-19_403.json\"\n",
    "filename_qwen25_coder_32b = \"experiment_3_config2__few_shot_CoT__Qwen-Qwen2.5-Coder-32B-Instruct-GPTQ-Int4_2025.01.03_23-18-16_403.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load = (\n",
    "    (os.path.join(RESULTS_PATH, filename_gemini_1_0), \"gemini_1_0\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_gemini_1_5), \"gemini_1_5\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_llama3_8b), \"llama3_8b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_llama31_70b), \"llama31_70b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_gpt4o), \"gpt_4o\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_gpt35_turbo), \"gpt35_turbo\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_phi3_medium), \"phi3_medium\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_phi4), \"phi_4\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen15_7b), \"qwen15_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen15_14b), \"qwen15_14b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen15_32b), \"qwen15_32b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen2_7b), \"qwen2_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen2_72b), \"qwen2_72b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_05b), \"qwen2.5_05b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_1b), \"qwen2.5_1b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_3b), \"qwen2.5_3b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_7b), \"qwen2.5_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_14b), \"qwen2.5_14b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_32b), \"qwen2.5_32b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_72b), \"qwen2.5_72b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_05b), \"qwen2.5_coder_05b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_1b), \"qwen2.5_coder_1b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_3b), \"qwen2.5_coder_3b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_7b), \"qwen2.5_coder_7b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_14b), \"qwen2.5_coder_14b\"),\n",
    "    (os.path.join(RESULTS_PATH, filename_qwen25_coder_32b), \"qwen2.5_coder_32b\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "for file_path, df_name in files_to_load:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD = 2\n",
    "choices = ['TP', 'FP', 'TN', 'FN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for gemini_1_0:\n",
      "TP    269\n",
      "FP    113\n",
      "TN     15\n",
      "FN      6\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for gemini_1_5:\n",
      "TP    266\n",
      "FP     28\n",
      "TN    100\n",
      "FN      9\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for llama3_8b:\n",
      "TP    274\n",
      "FP    119\n",
      "TN      9\n",
      "FN      1\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for llama31_70b:\n",
      "TP    251\n",
      "FP     16\n",
      "TN    112\n",
      "FN     24\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for gpt_4o:\n",
      "TP    275\n",
      "FP     78\n",
      "TN     50\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for gpt35_turbo:\n",
      "TP    271\n",
      "FP    113\n",
      "TN     15\n",
      "FN      4\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for phi3_medium:\n",
      "TP    275\n",
      "FP    112\n",
      "TN     16\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for phi_4:\n",
      "TP    275\n",
      "FP     52\n",
      "TN     76\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen15_7b:\n",
      "TP    272\n",
      "FP    127\n",
      "TN      1\n",
      "FN      3\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen15_14b:\n",
      "TP    259\n",
      "FP    106\n",
      "TN     22\n",
      "FN     16\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen15_32b:\n",
      "TP    263\n",
      "FP     95\n",
      "TN     33\n",
      "FN     12\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2_7b:\n",
      "TP    268\n",
      "FP    104\n",
      "TN     24\n",
      "FN      7\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2_72b:\n",
      "TP    274\n",
      "FP     83\n",
      "TN     45\n",
      "FN      1\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_05b:\n",
      "TP    233\n",
      "FP    112\n",
      "TN     16\n",
      "FN     42\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_1b:\n",
      "TP    266\n",
      "FP    119\n",
      "TN      9\n",
      "FN      9\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_3b:\n",
      "TP    268\n",
      "FP    116\n",
      "TN     12\n",
      "FN      7\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_7b:\n",
      "TP    269\n",
      "FP    118\n",
      "TN     10\n",
      "FN      6\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_14b:\n",
      "TP    272\n",
      "FP     51\n",
      "TN     77\n",
      "FN      3\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_32b:\n",
      "TP    275\n",
      "FP     57\n",
      "TN     71\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_72b:\n",
      "TP    275\n",
      "FP     80\n",
      "TN     48\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_05b:\n",
      "TP    275\n",
      "FP    128\n",
      "TN      0\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_1b:\n",
      "TP    266\n",
      "FP    126\n",
      "TN      2\n",
      "FN      9\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_3b:\n",
      "TP    268\n",
      "FP    123\n",
      "TN      5\n",
      "FN      7\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_7b:\n",
      "TP    274\n",
      "FP    122\n",
      "TN      6\n",
      "FN      1\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_14b:\n",
      "TP    269\n",
      "FP     72\n",
      "TN     56\n",
      "FN      6\n",
      "Name: llm_classification, dtype: int64\n",
      "\n",
      "Confusion Matrix for qwen2.5_coder_32b:\n",
      "TP    273\n",
      "FP     59\n",
      "TN     69\n",
      "FN      2\n",
      "Name: llm_classification, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dataframes.values():\n",
    "    df[\"llm_vul_decision\"] = np.where(df[\"threshold_value\"] < 0.0, True, df[\"threshold_value\"] >= TRESHOLD)\n",
    "    \n",
    "    conditions = [\n",
    "        (df[\"real_vulnerability\"] == True) & (df[\"llm_vul_decision\"] == True),\n",
    "        (df[\"real_vulnerability\"] == False) & (df[\"llm_vul_decision\"] == True),\n",
    "        (df[\"real_vulnerability\"] == False) & (df[\"llm_vul_decision\"] == False),\n",
    "        (df[\"real_vulnerability\"] == True) & (df[\"llm_vul_decision\"] == False)\n",
    "    ]\n",
    "    df[\"llm_classification\"] = np.select(conditions, choices)\n",
    "\n",
    "for model, df in dataframes.items():\n",
    "    print(f\"Confusion Matrix for {model}:\")\n",
    "    print(df[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_RESULTS_PATH = 'results/sc/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_phi4_sc1 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.20_17-53-56_403.json\"\n",
    "filename_phi4_sc2 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.21_23-09-57_403.json\"\n",
    "filename_phi4_sc3 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.22_11-03-37_403.json\"\n",
    "filename_phi4_sc4 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.22_12-48-26_403.json\"\n",
    "filename_phi4_sc5 = \"experiment_5_sc_config2__few_shot_CoT__microsoft-phi-4_2025.01.22_14-03-20_403.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load_sc_phi4 = (\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc1), \"phi_4 sc1\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc2), \"phi_4 sc2\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc3), \"phi_4 sc3\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc4), \"phi_4 sc4\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_phi4_sc5), \"phi_4 sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_sc_phi4:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD_PHI_4 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= TRESHOLD) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Phi4 SC dataframe\n",
      "TP    275\n",
      "FP     52\n",
      "TN     76\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Phi4 SC dataframe\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qwen 2.5 32B Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_qwen_sc1 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.23_17-22-31_403.json\"\n",
    "filename_qwen_sc2 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.23_23-18-22_403.json\"\n",
    "filename_qwen_sc3 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.24_13-24-46_403.json\"\n",
    "filename_qwen_sc4 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2025.01.24_18-09-55_403.json\"\n",
    "filename_qwen_sc5 = \"experiment_5_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct_2024.12.31_00-11-19_403.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load_sc_qwen25_32b = (\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc1), \"Qwen2.5 sc1\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc2), \"Qwen2.5 sc2\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc3), \"Qwen2.5 sc3\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc4), \"Qwen2.5 sc4\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_qwen_sc5), \"Qwen2.5 sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc_qwen = {}\n",
    "for file_path, df_name in files_to_load_sc_qwen25_32b:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc_qwen[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes_sc_qwen.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD_QWEN25_32B = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Qwen2.5 32B SC dataframe\n",
      "TP    275\n",
      "FP     48\n",
      "TN     80\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "for _, df in dataframes_sc_qwen.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= TRESHOLD_QWEN25_32B) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent_qwen = list(dataframes_sc_qwen.values())[0].copy()\n",
    "dfs_qwen = list(dataframes_sc_qwen.values())\n",
    "dfs_other = [df for df in dfs_qwen if df is not list(dataframes_sc_qwen.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent_qwen.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs_qwen]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent_qwen.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent_qwen.at[idx, 'llm_vul_decision'] = consensus\n",
    "\n",
    "for _, _ in dataframes_sc_qwen.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == True) & (df_sc_consistent_qwen['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == False) & (df_sc_consistent_qwen['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == False) & (df_sc_consistent_qwen['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent_qwen['real_vulnerability'] == True) & (df_sc_consistent_qwen['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent_qwen['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Qwen2.5 32B SC dataframe\")\n",
    "print(df_sc_consistent_qwen[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent_qwen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_gpt4o_sc1 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.06.19_00-54-42_403.json\"\n",
    "filename_gpt4o_sc2 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_15-43-27_403.json\"\n",
    "filename_gpt4o_sc3 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_17-49-47_403.json\"\n",
    "filename_gpt4o_sc4 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_18-52-38_403.json\"\n",
    "filename_gpt4o_sc5 = \"experiment_3_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.07_23-14-22_403.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load_sc_gpt4o = (\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc1), \"GPT-4o sc1\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc2), \"GPT-4o sc2\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc3), \"GPT-4o sc3\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc4), \"GPT-4o sc4\"),\n",
    "  (os.path.join(SC_RESULTS_PATH, filename_gpt4o_sc5), \"GPT-4o sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc_gpt4o = {}\n",
    "for file_path, df_name in files_to_load_sc_gpt4o:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"name\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc_gpt4o[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(spotbugs_dataset[\"name\"], spotbugs_dataset[\"real vulnerability\"]))\n",
    "for df in dataframes_sc_gpt4o.values():\n",
    "    df[\"real_vulnerability\"] = df[\"name\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD_GPT4O = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for GPT-4o SC dataframe\n",
      "TP    275\n",
      "FP     48\n",
      "TN     80\n",
      "FN      0\n",
      "Name: llm_classification, dtype: int64\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "for _, df in dataframes_sc_gpt4o.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= TRESHOLD_GPT4O) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent_gpt4o = list(dataframes_sc_gpt4o.values())[0].copy()\n",
    "dfs_gpt4o = list(dataframes_sc_gpt4o.values())\n",
    "dfs_other = [df for df in dfs_gpt4o if df is not list(dataframes_sc_gpt4o.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent_gpt4o.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs_gpt4o]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent_gpt4o.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent_gpt4o.at[idx, 'llm_vul_decision'] = consensus\n",
    "\n",
    "for _, _ in dataframes_sc_gpt4o.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == True) & (df_sc_consistent_gpt4o['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == False) & (df_sc_consistent_gpt4o['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == False) & (df_sc_consistent_gpt4o['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent_gpt4o['real_vulnerability'] == True) & (df_sc_consistent_gpt4o['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent_gpt4o['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for GPT-4o SC dataframe\")\n",
    "print(df_sc_consistent_gpt4o[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent_gpt4o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnestix (Real World Dataset)\n",
    "\n",
    "To demonstrate that our approach is not only effective on benchmark datasets but also applicable to real-world security analysis, we applied it to the open-source project Mnestix, developed by XITASO GmbH. This analysis allowed us to validate the approach on actual software weaknesses while ensuring transparency in discussing the findings.\n",
    "\n",
    "We utilized multiple SAST tools to analyze the Mnestix codebase, which includes components written in C, TypeScript, and infrastructure code, as well as BASXY, an open-source Java codebase. The selected tools—CodeQL, Semgrep, SpotBugs with FindSecBugs, Checkov, and KICS—enabled us to cover a broad range of security weaknesses across different programming paradigms. The findings from these SAST tools were manually labeled by different security experts and then assessed by the previously identified best-performing LLMs for our specific use case: GPT-4o, Qwen2.5 32B, and Phi-4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNESTIX Results\n",
    "CHECKOV_MNESTIX_RESULTS_FILE_PATH = \"results/mnestix/tool_results/checkov_labeled_results.xlsx\"\n",
    "CODEQL_MNESTIX_RESULTS_FILE_PATH = \"results/mnestix/tool_results/code_ql_labeled_results.xlsx\"\n",
    "KICS_MNESTIX_RESULTS_FILE_PATH = \"results/mnestix/tool_results/kics_labled_results.xlsx\"\n",
    "SEMGREP_MNESTIX_RESULTS_FILE_PATH = \"results/mnestix/tool_results/semgrep_labeled_results.xlsx\"\n",
    "\n",
    "#BASYX Results\n",
    "SPOTBUGS_AAS_ENV_RESULTS_FILE_PATH = \"results/mnestix/tool_results/spotbugs_aas_env_labeled_report.xlsx\"\n",
    "SPOTBUGS_BASYX_COMPONENTS_RESULTS_FILE_PATH = \"results/mnestix/tool_results/spotbugs_basyx_labeled_report.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkov_mnestix_results = pd.read_excel(CHECKOV_MNESTIX_RESULTS_FILE_PATH)\n",
    "checkov_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "codeql_mnestix_results = pd.read_excel(CODEQL_MNESTIX_RESULTS_FILE_PATH)\n",
    "codeql_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "kics_mnestix_results = pd.read_excel(KICS_MNESTIX_RESULTS_FILE_PATH)\n",
    "kics_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "semgrep_mnestix_results = pd.read_excel(SEMGREP_MNESTIX_RESULTS_FILE_PATH)\n",
    "semgrep_mnestix_results.set_index('id', inplace=True)\n",
    "\n",
    "spotbugs_aas_env_results = pd.read_excel(SPOTBUGS_AAS_ENV_RESULTS_FILE_PATH)\n",
    "spotbugs_aas_env_results.set_index('id', inplace=True)\n",
    "\n",
    "spotbugs_basyx_components_results = pd.read_excel(SPOTBUGS_BASYX_COMPONENTS_RESULTS_FILE_PATH)\n",
    "spotbugs_basyx_components_results.set_index('id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to every SAST scanner having different column names, we need to map them to a common set of column names\n",
    "relevant_columns = ['scanner', 'category', 'cwe', 'line of code', 'type', 'method', 'file', 'description', 'classification']\n",
    "\n",
    "spotbugs_columns = {\n",
    "    'scanner': 'scanner', \n",
    "    'type': 'type', \n",
    "    'cweid': 'cwe', \n",
    "    'category': 'category', \n",
    "    'method': 'method', \n",
    "    'sourceLine': 'line of code', \n",
    "    'classification': 'classification', \n",
    "    'sourceFile': 'file'\n",
    "}\n",
    "\n",
    "semgrep_columns = {\n",
    "    'scanner': 'scanner', \n",
    "    'cweid': 'cwe', \n",
    "    'category': 'category', \n",
    "    'start_line': 'line of code', \n",
    "    'classification': 'classification', \n",
    "    'path': 'file', \n",
    "    'message': 'description'\n",
    "}\n",
    "\n",
    "kics_columns = {\n",
    "        'scanner': 'scanner', \n",
    "        'Category': 'category', \n",
    "        'Line': 'line of code', \n",
    "        'classification': 'classification', \n",
    "        'File Name': 'file', \n",
    "        'Issue Type': 'type',\n",
    "        'Description': 'description'\n",
    "}\n",
    "\n",
    "codeql_columns = {\n",
    "        'scanner': 'scanner', \n",
    "        'cwe_id':'cwe', \n",
    "        'start_line': 'line of code', \n",
    "        'rule_name':'type', \n",
    "        'file_name': 'file',\n",
    "        'classification': 'classification', \n",
    "        'message': 'description'\n",
    "}\n",
    "\n",
    "checkov_columns = {\n",
    "        'scanner': 'scanner', \n",
    "        'line range': 'line of code', \n",
    "        'file_path': 'file',\n",
    "        'classification': 'classification', \n",
    "        'check_name': 'description',\n",
    "        'check_id': 'type'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkov_mnestix_results.rename(columns=checkov_columns, inplace=True)\n",
    "codeql_mnestix_results.rename(columns=codeql_columns, inplace=True)\n",
    "kics_mnestix_results.rename(columns=kics_columns, inplace=True)\n",
    "semgrep_mnestix_results.rename(columns=semgrep_columns, inplace=True)\n",
    "spotbugs_aas_env_results.rename(columns=spotbugs_columns, inplace=True)\n",
    "spotbugs_basyx_components_results.rename(columns=spotbugs_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in relevant_columns:\n",
    "  if col not in checkov_mnestix_results.columns:\n",
    "    checkov_mnestix_results[col] = None\n",
    "  if col not in codeql_mnestix_results.columns:\n",
    "    codeql_mnestix_results[col] = None\n",
    "  if col not in kics_mnestix_results.columns:\n",
    "    kics_mnestix_results[col] = None\n",
    "  if col not in semgrep_mnestix_results.columns:\n",
    "    semgrep_mnestix_results[col] = None\n",
    "  if col not in spotbugs_aas_env_results.columns:\n",
    "    spotbugs_aas_env_results[col] = None\n",
    "  if col not in spotbugs_basyx_components_results.columns:\n",
    "    spotbugs_basyx_components_results[col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkov = checkov_mnestix_results[relevant_columns]\n",
    "df_codeql = codeql_mnestix_results[relevant_columns]\n",
    "df_kics = kics_mnestix_results[relevant_columns]\n",
    "df_semgrep = semgrep_mnestix_results[relevant_columns]\n",
    "df_soptbugs_aas_env_results = spotbugs_aas_env_results[relevant_columns]\n",
    "df_soptbugs_basyx_copmponents_results = spotbugs_basyx_components_results[relevant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([df_checkov, df_codeql, df_kics, df_semgrep, df_soptbugs_aas_env_results, df_soptbugs_basyx_copmponents_results], ignore_index=True)\n",
    "combined_df['findings_id'] = combined_df.index.astype(str)\n",
    "combined_df['real vulnerability'] = combined_df['classification'].apply(lambda x: True if x == 'TP' else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_RESULTS_PATH = 'results/mnestix/model_results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qwen2.5 32B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_THRESHOLD_QWEN25_32B = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_qwen25_32b_sc_1 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.24_11-22-50_114.json\"\n",
    "filename_qwen25_32b_sc_2 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.24_11-47-10_114.json\"\n",
    "filename_qwen25_32b_sc_3 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.25_15-42-54_114.json\"\n",
    "filename_qwen25_32b_sc_4 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.25_16-24-15_114.json\"\n",
    "filename_qwen25_32b_sc_5 = \"experiment_6_sc_config2__few_shot_CoT__Qwen-Qwen2.5-32B-Instruct-GPTQ-Int4_2025.02.25_22-33-05_114.json\"\n",
    "\n",
    "files_to_load_mnestix_sc_qwen = (\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_1), \"Qwen2.5 32B sc1\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_2), \"Qwen2.5 32B sc2\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_3), \"Qwen2.5 32B sc3\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_4), \"Qwen2.5 32B sc4\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_qwen25_32b_sc_5), \"Qwen2.5 32B sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_mnestix_sc_qwen:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"findings_id\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(combined_df[\"findings_id\"], combined_df[\"real vulnerability\"]))\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"findings_id\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= MNESTIX_THRESHOLD_QWEN25_32B) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for QWen SC dataframe\n",
      "TP    49\n",
      "FP    46\n",
      "TN    19\n",
      "FN     0\n",
      "Name: llm_classification, dtype: int64\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for QWen SC dataframe\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phi-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_PHI4_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_phi_sc_1 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_15-17-48_114.json\"\n",
    "filename_phi_sc_2 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_16-59-12_114.json\"\n",
    "filename_phi_sc_3 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_19-10-57_114.json\"\n",
    "filename_phi_sc_4 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.24_23-06-49_114.json\"\n",
    "filename_phi_sc_5 = \"experiment_6_sc_config2__few_shot_CoT__microsoft-phi-4_2025.02.25_14-41-29_114.json\"\n",
    "\n",
    "files_to_load_sc_phi4 = (\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_1), \"phi_4 sc1\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_2), \"phi_4 sc2\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_3), \"phi_4 sc3\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_4), \"phi_4 sc4\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_phi_sc_5), \"phi_4 sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_sc_phi4:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"findings_id\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(combined_df[\"findings_id\"], combined_df[\"real vulnerability\"]))\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"findings_id\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= MNESTIX_PHI4_THRESHOLD) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Phi-4 SC dataframe\n",
      "TP    49\n",
      "FP    43\n",
      "TN    22\n",
      "FN     0\n",
      "Name: llm_classification, dtype: int64\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Phi-4 SC dataframe\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNESTIX_GPT4O_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_gpt4o_sc_1 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.07.31_23-34-18_114.json\"\n",
    "filename_gpt4o_sc_2 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.01_00-09-04_114.json\"\n",
    "filename_gpt4o_sc_3 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.01_00-33-19_114.json\"\n",
    "filename_gpt4o_sc_4 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.01_13-15-25_114.json\"\n",
    "filename_gpt4o_sc_5 = \"experiment_6_sc_config2__few_shot_CoT__gpt-4o-2024-05-13_2024.08.10_16-56-32_114.json\"\n",
    "\n",
    "files_to_load_sc_gpt4o = (\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_1), \"GPT-4o sc1\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_2), \"GPT-4o sc2\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_3), \"GPT-4o sc3\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_4), \"GPT-4o sc4\"),\n",
    "  (os.path.join(MNESTIX_RESULTS_PATH, filename_gpt4o_sc_5), \"GPT-4o sc5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_sc = {}\n",
    "for file_path, df_name in files_to_load_sc_gpt4o:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    vulnerabilities_list_sc = [\n",
    "        {**value, \"findings_id\": key} for key, value in json_data[\"vulnerabilities\"].items()\n",
    "    ]\n",
    "    \n",
    "    df = pd.json_normalize(vulnerabilities_list_sc)\n",
    "    df[\"Date\"] = json_data[\"Date\"]\n",
    "    dataframes_sc[df_name] = df\n",
    "\n",
    "real_vulnerability_map = dict(zip(combined_df[\"findings_id\"], combined_df[\"real vulnerability\"]))\n",
    "for df in dataframes_sc.values():\n",
    "    df[\"real_vulnerability\"] = df[\"findings_id\"].map(real_vulnerability_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, df in dataframes_sc.items():\n",
    "  df['llm_vul_decision'] = np.where(df['threshold_value'] < 0.0, True, df['threshold_value'] >= MNESTIX_GPT4O_THRESHOLD) # due to handling invalid LLM responses we label threshold_value < 0 as True, as those weaknesses must be reviewed by humans\n",
    "\n",
    "\n",
    "df_sc_consistent = list(dataframes_sc.values())[0].copy()\n",
    "dfs = list(dataframes_sc.values())\n",
    "dfs_other = [df for df in dfs if df is not list(dataframes_sc.values())[0]]\n",
    "\n",
    "\n",
    "for idx in df_sc_consistent.index:\n",
    "  decisions = [df.loc[idx, 'llm_vul_decision'] for df in dfs]\n",
    "  count_true = decisions.count(True)\n",
    "  count_false = decisions.count(False)\n",
    "  consensus = df_sc_consistent.loc[idx, 'llm_vul_decision'] if count_true == count_false else (True if count_true > count_false else False)\n",
    "  df_sc_consistent.at[idx, 'llm_vul_decision'] = consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Phi-4 SC dataframe\n",
      "TP    48\n",
      "FP    41\n",
      "TN    24\n",
      "FN     1\n",
      "Name: llm_classification, dtype: int64\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "for _, _ in dataframes_sc.items():\n",
    "  conditions = [\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == True),\n",
    "    (df_sc_consistent['real_vulnerability'] == False) & (df_sc_consistent['llm_vul_decision'] == False),\n",
    "    (df_sc_consistent['real_vulnerability'] == True) & (df_sc_consistent['llm_vul_decision'] == False)\n",
    "  ]\n",
    "  choices = ['TP', 'FP', 'TN', 'FN']\n",
    "  df_sc_consistent['llm_classification'] = np.select(conditions, choices)\n",
    "\n",
    "print(f\"Confusion Matrix for Phi-4 SC dataframe\")\n",
    "print(df_sc_consistent[\"llm_classification\"].value_counts().reindex(choices, fill_value=0))\n",
    "print(len(df_sc_consistent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
